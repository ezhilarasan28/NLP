{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THENKUZHALI S\n",
    "225229143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_JXsYl9NXbR"
   },
   "source": [
    "# Lab10. Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XvmuznDJMtRz"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "11snCgVeOEZy"
   },
   "outputs": [],
   "source": [
    "sentence = \"Rajkumar said on Monday that WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E.Lynch,  the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibilty for repairing generations of miscommunication and mistrust fell to law enforcement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PFxrvMQRNQLO",
    "outputId": "387f1c9c-21cf-479c-e5cc-b32ac4975aa6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "axn5XPNeSeW-",
    "outputId": "bff915c0-2fe1-42f9-f901-7e05a0de1bd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R2y_PYuZSms3",
    "outputId": "610fa77d-8667-49fb-f07c-670b2ca92393"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uoAEnDGwStm_",
    "outputId": "214427b8-e905-4bb3-f5c5-64d20e32e635"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4JWH4hMSVLv",
    "outputId": "e7f088a7-0d56-44b2-9dd2-43de5aa30320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Rajkumar/NNP)\n",
      "  said/VBD\n",
      "  on/IN\n",
      "  Monday/NNP\n",
      "  that/IN\n",
      "  (ORGANIZATION WASHINGTON/NNP)\n",
      "  --/:\n",
      "  In/IN\n",
      "  the/DT\n",
      "  wake/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  string/NN\n",
      "  of/IN\n",
      "  abuses/NNS\n",
      "  by/IN\n",
      "  (GPE New/NNP York/NNP)\n",
      "  police/NN\n",
      "  officers/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1990s/CD\n",
      "  ,/,\n",
      "  (PERSON Loretta/NNP E.Lynch/NNP)\n",
      "  ,/,\n",
      "  the/DT\n",
      "  top/JJ\n",
      "  federal/JJ\n",
      "  prosecutor/NN\n",
      "  in/IN\n",
      "  (GPE Brooklyn/NNP)\n",
      "  ,/,\n",
      "  spoke/VBD\n",
      "  forcefully/RB\n",
      "  about/IN\n",
      "  the/DT\n",
      "  pain/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  broken/JJ\n",
      "  trust/NN\n",
      "  that/IN\n",
      "  African-Americans/NNP\n",
      "  felt/VBD\n",
      "  and/CC\n",
      "  said/VBD\n",
      "  the/DT\n",
      "  responsibilty/NN\n",
      "  for/IN\n",
      "  repairing/VBG\n",
      "  generations/NNS\n",
      "  of/IN\n",
      "  miscommunication/NN\n",
      "  and/CC\n",
      "  mistrust/NN\n",
      "  fell/VBD\n",
      "  to/TO\n",
      "  law/NN\n",
      "  enforcement/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(sentence)\n",
    "tags = pos_tag(tokens)\n",
    "ne_tree = ne_chunk(tags)\n",
    "print(ne_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iEIXSFBrSXrf"
   },
   "outputs": [],
   "source": [
    "#Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNDRzEFVUPkk",
    "outputId": "ece161ef-5c3c-4544-97c8-14b889d59ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'Rajkumar': 1, 'NNP': 1})]\n",
      "[Counter({'WASHINGTON': 1, 'NNP': 1})]\n",
      "[Counter({'New': 1, 'NNP': 1}), Counter({'York': 1, 'NNP': 1})]\n",
      "[Counter({'Loretta': 1, 'NNP': 1}), Counter({'E.Lynch': 1, 'NNP': 1})]\n",
      "[Counter({'Brooklyn': 1, 'NNP': 1})]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence))):\n",
    " if hasattr(chunk, 'label'):\n",
    "   print([Counter(label) for label in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xdzOzU0YUq6u"
   },
   "outputs": [],
   "source": [
    "#Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRv6b2l1U5T8",
    "outputId": "4fe3f1d8-cb28-4829-feca-206279a5f56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'New York', 'police officers', 'Loretta E.Lynch', 'Brooklyn']\n"
     ]
    }
   ],
   "source": [
    "my_sent = sentence\n",
    "word = nltk.word_tokenize(my_sent)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<NN><NNS>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m_zYeNX8cSOi",
    "outputId": "e8bf00b3-2fa5-4334-8749-5fd48173d180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'the wake', 'a string', 'New York', 'Loretta E.Lynch', 'the top federal prosecutor', 'Brooklyn', 'the pain', 'a broken trust', 'the responsibilty']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "-PGKOIGUWRPl"
   },
   "outputs": [],
   "source": [
    "#Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C1oYCuSeWkVs",
    "outputId": "cd088da9-4c45-4780-e358-c60bfb0ad84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rajkumar', 'NNP'), ('said', 'VBD'), ('on', 'IN'), ('Monday', 'NNP'), ('that', 'IN'), ('WASHINGTON', 'NNP'), ('--', ':'), ('In', 'IN'), Tree('NP', [('the', 'DT'), ('wake', 'NN')]), ('of', 'IN'), Tree('NP', [('a', 'DT'), ('string', 'NN')]), ('of', 'IN'), ('abuses', 'NNS'), ('by', 'IN'), ('New', 'NNP'), ('York', 'NNP'), ('police', 'NN'), ('officers', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('1990s', 'CD'), (',', ','), ('Loretta', 'NNP'), ('E.Lynch', 'NNP'), (',', ','), Tree('NP', [('the', 'DT'), ('top', 'JJ'), ('federal', 'JJ'), ('prosecutor', 'NN')]), ('in', 'IN'), ('Brooklyn', 'NNP'), (',', ','), ('spoke', 'VBD'), ('forcefully', 'RB'), ('about', 'IN'), Tree('NP', [('the', 'DT'), ('pain', 'NN')]), ('of', 'IN'), Tree('NP', [('a', 'DT'), ('broken', 'JJ'), ('trust', 'NN')]), ('that', 'IN'), ('African-Americans', 'NNP'), ('felt', 'VBD'), ('and', 'CC'), ('said', 'VBD'), Tree('NP', [('the', 'DT'), ('responsibilty', 'NN')]), ('for', 'IN'), ('repairing', 'VBG'), ('generations', 'NNS'), ('of', 'IN'), ('miscommunication', 'NN'), ('and', 'CC'), ('mistrust', 'NN'), ('fell', 'VBD'), ('to', 'TO'), ('law', 'NN'), ('enforcement', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "parse = cp.parse(tags)\n",
    "print(parse[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0h76wCHjc6a2",
    "outputId": "75230539-4aa7-4b35-d760-e482692c07d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rajkumar', 'WASHINGTON', 'the wake', 'a string', 'New York', 'Loretta E.Lynch', 'Brooklyn', 'the pain', 'the responsibilty']\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NP: {<DT><JACJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "duYbmVw-dI2H"
   },
   "outputs": [],
   "source": [
    "#EXERCISE-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "TzUXUROVdNk3"
   },
   "outputs": [],
   "source": [
    "sentence2 = \"European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vcctJ2K_d6u-"
   },
   "outputs": [],
   "source": [
    "#Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IT8MMgppeAim",
    "outputId": "87775cfb-991f-4a56-e6ae-c816ce422ac2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('GPE', [('European', 'JJ')]), ('authorities', 'NNS'), ('fined', 'VBD'), Tree('PERSON', [('Google', 'NNP')]), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('abusing', 'VBG'), ('its', 'PRP$'), ('power', 'NN'), ('in', 'IN'), ('the', 'DT'), ('mobile', 'JJ'), ('phone', 'NN'), ('market', 'NN'), ('and', 'CC'), ('ordered', 'VBD'), ('the', 'DT'), ('company', 'NN'), ('to', 'TO'), ('alter', 'VB'), ('its', 'PRP$'), ('practices', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "token=word_tokenize(sentence2)\n",
    "tag=nltk.pos_tag(token)\n",
    "ne_tree=ne_chunk(tag)\n",
    "print(ne_tree[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILkMpmk9eJQH",
    "outputId": "440a49d4-17df-448a-a1ec-ca82a972c835"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', '5.1', 'billion']\n"
     ]
    }
   ],
   "source": [
    "word = nltk.word_tokenize(sentence2)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<CD>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NTBTlSwXeBJu"
   },
   "outputs": [],
   "source": [
    "#Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EbPiqM_zeEwG",
    "outputId": "2564da1d-8dd2-4bc8-90bd-9143353ee80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['European', 'Google', 'a record', 'the mobile phone', 'the company']\n"
     ]
    }
   ],
   "source": [
    "word = nltk.word_tokenize(sentence2)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<DT><JJ>*<NN>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "c9kJ5nkAeRp2"
   },
   "outputs": [],
   "source": [
    "#EXERCISE - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Z4SgIUOjgyry"
   },
   "outputs": [],
   "source": [
    "fname = \"/content/food_recipes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "iBjdiBN-eblE"
   },
   "outputs": [],
   "source": [
    "with open(fname , 'r') as f:\n",
    "  content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8LpVFmshIDB",
    "outputId": "a12a84f6-d21d-40a6-a7b4-afc48eed20f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEEF TENDERLOIN STEAKS WITH SMOKY BACON-BOURBON SAUCE\n",
      "Serves: 4\n",
      "\n",
      "1 1/2 cups dry red wine\n",
      "3 cloves garlic\n",
      "1 3/4 cups beef broth\n",
      "1 1/4 cups chicken broth\n",
      "1 1/2 tablespoons tomato paste\n",
      "1 bay leaf\n",
      "1 sprig thyme\n",
      "8 ounces bacon cut into 1/4 inch pieces\n",
      "1 tablespoon flour\n",
      "1 tablespoon butter\n",
      "4 1 inch rib-eye steaks\n",
      "1 tablespoon bourbon whiskey\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhjp3QuHjpiu",
    "outputId": "8ec5c98d-f936-4a10-c9eb-b91f9b8e6de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('ORGANIZATION', [('BEEF', 'NNP')]), Tree('ORGANIZATION', [('TENDERLOIN', 'NNP')]), ('STEAKS', 'NNP'), ('WITH', 'NNP'), ('SMOKY', 'NNP'), ('BACON-BOURBON', 'NNP'), ('SAUCE', 'NNP'), ('Serves', 'VBZ'), (':', ':'), ('4', 'CD'), ('1', 'CD'), ('1/2', 'CD'), ('cups', 'NNS'), ('dry', 'JJ'), ('red', 'JJ'), ('wine', 'NN'), ('3', 'CD'), ('cloves', 'NNS'), ('garlic', 'JJ'), ('1', 'CD'), ('3/4', 'CD'), ('cups', 'NNS'), ('beef', 'VBD'), ('broth', 'DT'), ('1', 'CD'), ('1/4', 'CD'), ('cups', 'NNS'), ('chicken', 'VBP'), ('broth', 'DT'), ('1', 'CD'), ('1/2', 'CD'), ('tablespoons', 'NNS'), ('tomato', 'VBP'), ('paste', 'NN'), ('1', 'CD'), ('bay', 'NN'), ('leaf', 'NN'), ('1', 'CD'), ('sprig', 'NN'), ('thyme', 'NN'), ('8', 'CD'), ('ounces', 'NNS'), ('bacon', 'JJ'), ('cut', 'VBD'), ('into', 'IN'), ('1/4', 'CD'), ('inch', 'NN'), ('pieces', 'NNS'), ('1', 'CD'), ('tablespoon', 'RB'), ('flour', 'JJ'), ('1', 'CD'), ('tablespoon', 'NN'), ('butter', 'NN'), ('4', 'CD'), ('1', 'CD'), ('inch', 'JJ'), ('rib-eye', 'JJ'), ('steaks', 'NNS'), ('1', 'CD'), ('tablespoon', 'NN'), ('bourbon', 'NN'), ('whiskey', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "token=word_tokenize(content)\n",
    "tag=nltk.pos_tag(token)\n",
    "ne_tree=ne_chunk(tag)\n",
    "print(ne_tree[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhYti2sGmWxO",
    "outputId": "f838b776-7f87-4611-f735-7480d63887e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({'BEEF': 1, 'NNP': 1})]\n",
      "[Counter({'TENDERLOIN': 1, 'NNP': 1})]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(content))):\n",
    " if hasattr(chunk, 'label'):\n",
    "   print([Counter(label) for label in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UCBbnesqiURH",
    "outputId": "cae589f1-c05f-4ba8-9a6b-eef94fdaf0c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEEF', 'TENDERLOIN', 'cups dry red wine', 'cloves garlic', 'cups', 'cups', 'tablespoons', 'paste', 'bay leaf', 'sprig thyme', 'ounces bacon', 'inch', 'pieces', 'flour', 'tablespoon butter', 'inch rib-eye', 'steaks', 'tablespoon bourbon whiskey']\n"
     ]
    }
   ],
   "source": [
    "word = nltk.word_tokenize(content)\n",
    "pos_tag = nltk.pos_tag(word)\n",
    "chunk = nltk.ne_chunk(pos_tag)\n",
    "grammar = \"NP: {<NNS>*<JJ>*<NN>*}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(chunk)\n",
    "NE = [ \" \".join(w for w, t in ele) for ele in result if isinstance(ele, nltk.Tree)]\n",
    "print (NE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S55o_yKi2eY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
